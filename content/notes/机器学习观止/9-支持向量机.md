## 9.1 SVM可以做什么
寻找能将数据正确分类的最优决策面。
当样本点的维度是$n$维的时候，那么能将它们分隔开的决策面就需要是$n-1$维。
![500](non-linear-svm.jpg)
![420](multi-class-svm.jpg)
## 9.2 SVM的数学表述
### 9.2.1 决策面的数学表述
决策面可以表示为各个变量的线性组合：
$$
\theta_0+\theta_1x_1+...+\theta_nx_n
$$
其中$\theta_0$是偏置项，其余为权重项。用向量来表示即
$$
\boldsymbol w^T \boldsymbol  x
$$
在参数调整时，需要沿着决策面的垂直方向进行调整，即使得$\boldsymbol w^T \cdot \boldsymbol x = 0$

### 9.2.2 分类间隔的数学表述

参数点到决策面的距离
$$
d = \frac{|\boldsymbol w^T \boldsymbol X + \gamma|}{||\omega||}
$$

9.2.3 